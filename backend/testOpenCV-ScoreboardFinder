import cv2
import numpy as np

def get_total_frames(video_path):
    """Get the total number of frames in the video."""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    return total_frames

def get_frame_at_index(video_path, index):
    """Get a specific frame by its index."""
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_POS_FRAMES, index)
    ret, frame = cap.read()
    cap.release()
    return ret, frame

def get_bottom_fourth(frame):
    """Extract the bottom fourth (Region of Interest) from a frame."""
    height, _, _ = frame.shape
    roi = frame[int(3 * height / 4):, :]
    return roi

def compute_frame_difference(prev_frame, current_frame):
    """Compute the absolute difference between two frames."""
    return cv2.absdiff(prev_frame, current_frame)

def threshold_difference(diff_frame, threshold_value=25):
    """Apply thresholding to isolate changes in the difference frame."""
    gray_diff = cv2.cvtColor(diff_frame, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray_diff, threshold_value, 255, cv2.THRESH_BINARY)
    return thresh

def blacken_non_static_regions(prev_roi, current_roi, thresh):
    """Blackens non-static regions in the current region of interest (ROI)."""
    static_mask = cv2.bitwise_not(thresh)
    static_frame = cv2.bitwise_and(current_roi, current_roi, mask=static_mask)
    return static_frame

def accumulate_static_frames(accumulated_frame, static_frame):
    """
    Accumulates static frames over time to identify consistently static regions.

    Args:
        accumulated_frame (ndarray): Previously accumulated static frame.
        static_frame (ndarray): Current static frame.

    Returns:
        ndarray: Updated accumulated frame.
    """
    # Ensure both frames are float32 for compatibility with cv2.addWeighted
    static_frame = static_frame.astype(np.float32)
    accumulated_frame = static_frame.astype(np.float32)

    if accumulated_frame is None:
        # Initialize accumulated_frame with the same shape and type as static_frame
        accumulated_frame = np.zeros_like(static_frame, dtype=np.float32)

    # Ensure shapes match
    if accumulated_frame.shape != static_frame.shape:
        static_frame = cv2.resize(static_frame, (accumulated_frame.shape[1], accumulated_frame.shape[0]))

    # Weighted accumulation
    alpha = 0.05  # Weight for the current frame
    #print("Static Frame Type:", static_frame.dtype, "Shape:", static_frame.shape)
    #print("Accumulated Frame Type:", accumulated_frame.dtype, "Shape:", accumulated_frame.shape)

    accumulated_frame = cv2.addWeighted(static_frame, alpha, accumulated_frame, 1 - alpha, 0)

    # Convert back to 8-bit for display
    return cv2.convertScaleAbs(accumulated_frame)



def main(video_path, num_frames=30):
    """Main function to process only 30 frames from the video."""
    total_frames = get_total_frames(video_path)
    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)

    accumulated_frame = None
    prev_roi = None

    for idx in frame_indices:
        ret, frame = get_frame_at_index(video_path, idx)
        if not ret:
            print(f"Error reading frame at index {idx}")
            continue

        # Extract Region of Interest (ROI)
        roi = get_bottom_fourth(frame)

        # Initialize prev_roi on the first iteration
        if prev_roi is None:
            prev_roi = roi
            continue

        # Compute frame difference
        diff_frame = compute_frame_difference(prev_roi, roi)

        # Threshold the difference
        thresh_frame = threshold_difference(diff_frame)

        # Blacken non-static regions
        static_frame = blacken_non_static_regions(prev_roi, roi, thresh_frame)

        if accumulated_frame is not None and accumulated_frame.shape != static_frame.shape:
            static_frame = cv2.resize(static_frame, (accumulated_frame.shape[1], accumulated_frame.shape[0]))

        # Accumulate Frames
        accumulated_frame = accumulate_static_frames(accumulated_frame, static_frame)

        # Combine the original ROI and the static frame side by side
        combined_display = cv2.hconcat([roi, accumulated_frame])

        # Display the combined view
        cv2.imshow('Original ROI and Augmented ROI', combined_display)

        # Update prev_roi
        prev_roi = roi

        # Wait for a short duration to view each frame (adjust as needed)
        if cv2.waitKey(500) & 0xFF == ord('q'):  # Press 'q' to quit early
            break

    cv2.destroyAllWindows()

# Run the main function with the video path
main('media/videoplayback.mp4')
